{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-based Algorithm & Similarity Metrics\n",
    "\n",
    "Distance-based algorithms are machine learning algorithms that classify queries by computing distances between these queries and a number of internally stored exemplars.\n",
    "\n",
    "In Milvus, similarity metrics are used to measure similarities among vectors. Choosing a good distance metric helps improve the classification and clustering performance significantly.\n",
    "\n",
    "The following link shows how these widely used similarity metrics fit with various input data forms and Milvus indexes: [Milvus Similarity Metrics](https://milvus.io/docs/metric.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidian Distance (L2)\n",
    "\n",
    "Euclidean distance measures the length of a segment that connects 2 points.\n",
    "\n",
    "$$d(a,b) = d(b,a) = \\sqrt{\\Sigma_{i=0}^{n-1}(b_i - a_i)^2}$$\n",
    "\n",
    "Where $a = (a0, a1,..., an-1)$ and $b = (b0, b1,..., bn-1)$ are two points in n-dimensional Euclidean space.\n",
    "\n",
    "Milvus only caculates the value before applying square root when Euclidean distance is chosen as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# Python code to find Euclidean distance using linalg.norm()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# initializing points in\n",
    "# numpy arrays\n",
    "point1 = np.array((1, 2, 3))\n",
    "point2 = np.array((1, 1, 1))\n",
    "\n",
    "# calculating Euclidean distance\n",
    "# using linalg.norm()\n",
    "dist = np.linalg.norm(point1 - point2)\n",
    "\n",
    "# printing Euclidean distance\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# Python code to find Euclidean distance using dot()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# initializing points in\n",
    "# numpy arrays\n",
    "point1 = np.array((1, 2, 3))\n",
    "point2 = np.array((1, 1, 1))\n",
    "\n",
    "# subtracting vector\n",
    "temp = point1 - point2\n",
    "\n",
    "# doing dot product\n",
    "# for finding\n",
    "# sum of the squares\n",
    "sum_sq = np.dot(temp.T, temp)\n",
    "\n",
    "# Doing squareroot and\n",
    "# printing Euclidean distance\n",
    "print(np.sqrt(sum_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# Python code to find Euclidean distance\n",
    "# Using sum() and square()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialising points in numpy arrays\n",
    "point1 = np.array((1, 2, 3))\n",
    "point2 = np.array((1, 1, 1))\n",
    "\n",
    "# Finding sum of squares\n",
    "sum_sq = np.sum(np.square(point1 - point2))\n",
    "\n",
    "# Doing squareroot and printing Euclidean distance\n",
    "print(np.sqrt(sum_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 152.28944029130207\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "point_list = [\n",
    "    [0, 0, 0],  # 0\n",
    "    [6.888437030500963, 5.159088058806049, -1.5885683833831],\n",
    "    [2.0667720363602307, 5.384582486178219, -3.4898856343748133],\n",
    "    [7.742743817055683, 1.4508370077567676, -3.957946551327696],\n",
    "    [9.410384606156306, 9.613094711663472, -3.864209434979891],\n",
    "    [5.047141494150383, 14.72917879480795, -1.4968295014732576],\n",
    "    [0.05726832139919402, 22.924103914172754, 8.158880019279806],\n",
    "    [6.261613041330982, 30.96742292296441, 4.361831405666459],\n",
    "    [10.858248006533554, 38.94418868232428, 8.041510043975286],\n",
    "    [10.30110231558782, 30.958212843691598, 6.724946753050958],\n",
    "    [12.518841784463852, 39.21843390844956, 16.057074108466132],\n",
    "]\n",
    "\n",
    "def dist(list):\n",
    "    cummulativeDist = 0\n",
    "\n",
    "    # iterate over sets of points\n",
    "    for i in range(len(list) - 1):\n",
    "        coordInit = list[i]\n",
    "        coordFinal = list[i + 1]\n",
    "\n",
    "        # distance from one pt to the next\n",
    "        dist = math.sqrt(\n",
    "            ((coordInit[0] - coordFinal[0]) ** 2)\n",
    "            + ((coordInit[1] - coordFinal[2]) ** 2)\n",
    "            + ((coordInit[2] - coordFinal[2]) ** 2)\n",
    "        )\n",
    "\n",
    "        cummulativeDist += dist\n",
    "\n",
    "    return cummulativeDist\n",
    "\n",
    "\n",
    "print(f\"Distance: {dist(point_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner Product (IP)\n",
    "\n",
    "The IP distance between two embeddings are defined as follows:\n",
    "$$p(A,B) = A \\cdot B = \\sum^{n-1}_{i=0} a_i \\cdot b_i$$\n",
    "IP is more useful if you need to compare non-normalized data or when you care about magnitude and angle.\n",
    "\n",
    "**Note:** If you apply the IP distance metric to normalized embeddings, the result will be equivalent to calculating the cosine similarity between the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose X' is normalized from embedding X:\n",
    "\n",
    "$$X' = (x'_1, x'_2, \\dots, x'_n), X' \\in^n$$\n",
    "\n",
    "The correlation between the two embeddings is as follows:\n",
    "\n",
    "$$x'_i = \\frac{x_i}{||X||} = \\frac{x_i}{\\sqrt{\\sum_{i=1}^n(x_i)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1-D arrays:\n",
      "[6 2]\n",
      "[2 5]\n",
      "Inner Product of the two array is:\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Importing library\n",
    "import numpy as np\n",
    "\n",
    "# Creating two 1-D arrays\n",
    "array1 = np.array([6, 2])\n",
    "array2 = np.array([2, 5])\n",
    "\n",
    "print(\"Original 1-D arrays:\")\n",
    "print(array1)\n",
    "print(array2)\n",
    "\n",
    "# Output\n",
    "print(\"Inner Product of the two array is:\")\n",
    "result = np.inner(array1, array2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1-D arrays:\n",
      "[1 3 5]\n",
      "[0 1 5]\n",
      "Inner Product of the two array is:\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# Importing library\n",
    "import numpy as np\n",
    "\n",
    "# Creating two 1-D arrays\n",
    "array1 = np.array([1, 3, 5])\n",
    "array2 = np.array([0, 1, 5])\n",
    "\n",
    "print(\"Original 1-D arrays:\")\n",
    "print(array1)\n",
    "print(array2)\n",
    "\n",
    "# Output\n",
    "print(\"Inner Product of the two array is:\")\n",
    "result = np.inner(array1, array2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "Cosine similarity uses the cosine of the angle between two sets of vectors to measure how similar they are. You can think of the two sets of vectors as two line segments that start from the same origin ([0,0,...]) but point in different directions.\n",
    "\n",
    "To calculate the cosine similarity between two sets of vectors $A = (a_0, a_1,..., a_{n-1})$ and $B = (b_0, b_1,..., b_{n-1})$, use the following formula:\n",
    "\n",
    "$$\\cos \\theta=\\frac{\\sum_0^{n-1}\\left(a_i \\cdot b_i\\right)}{\\sqrt{\\sum_0^{n-1} a_i^2} \\cdot \\sqrt{\\sum_0^{n-1} b_i^2}}$$\n",
    "\n",
    "Note: The cosine similarity is always in the interval $[-1, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [2 1 2 3 2 9]\n",
      "B: [3 4 2 4 5 5]\n",
      "Cosine Similarity: 0.8188504723485274\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# define two lists or array\n",
    "A = np.array([2, 1, 2, 3, 2, 9])\n",
    "B = np.array([3, 4, 2, 4, 5, 5])\n",
    "\n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)\n",
    "\n",
    "# compute cosine similarity\n",
    "cosine = np.dot(A, B) / (norm(A) * norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ 2  1  2]\n",
      " [ 3  2  9]\n",
      " [-1  2 -3]]\n",
      "B:\n",
      " [3 4 2]\n",
      "Cosine Similarity:\n",
      " [ 0.86657824  0.67035541 -0.04962917]\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# define two lists or array\n",
    "A = np.array([[2, 1, 2], [3, 2, 9], [-1, 2, -3]])\n",
    "B = np.array([3, 4, 2])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"B:\\n\", B)\n",
    "\n",
    "# compute cosine similarity\n",
    "cosine = np.dot(A, B) / (norm(A, axis=1) * norm(B))\n",
    "print(\"Cosine Similarity:\\n\", cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Distance\n",
    "\n",
    "**Jaccard similarity** coefficient measures the similarity between two sample sets and is defined as the cardinality of the intersection of the defined sets divided by the cardinality of the union of them. It can only be applied to finite sample sets.\n",
    "\n",
    "$$J(A,B) = \\frac{|A \\cap B|}{|A| + |B| - |A\\cap B|}$$\n",
    "\n",
    "**Jaccard distance** measures the dissimilarity between data sets and is obtained by subtracting the Jaccard similarity coefficient from 1. For binary variables, Jaccard distance is equivalent to the Tanimoto coefficient.\n",
    "\n",
    "$$d_j(A, B)=1-J(A, B)=\\frac{|A \\cup B|-|A \\cap B|}{|A \\cup B|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.25\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    # intersection of two sets\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    # Unions of two sets\n",
    "    union = len(set1.union(set2))\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "set_a = {\"Geeks\", \"for\", \"Geeks\", \"NLP\", \"DSc\"}\n",
    "set_b = {\"Geek\", \"for\", \"Geeks\", \"DSc.\", \"ML\", \"DSA\"}\n",
    "\n",
    "similarity = jaccard_similarity(set_a, set_b)\n",
    "print(\"Jaccard Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance: 0.75\n"
     ]
    }
   ],
   "source": [
    "def jaccard_distance(set1, set2):\n",
    "    # Symmetric difference of two sets\n",
    "    Symmetric_difference = set1.symmetric_difference(set2)\n",
    "    # Unions of two sets\n",
    "    union = set1.union(set2)\n",
    "\n",
    "    return len(Symmetric_difference) / len(union)\n",
    "\n",
    "\n",
    "set_a = {\"Geeks\", \"for\", \"Geeks\", \"NLP\", \"DSc\"}\n",
    "set_b = {\"Geek\", \"for\", \"Geeks\", \"DSc.\", \"ML\", \"DSA\"}\n",
    "\n",
    "distance = jaccard_distance(set_a, set_b)\n",
    "print(\"Jaccard distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Index: 0.75\n",
      "Jaccard Distance: 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# predicted values\n",
    "y_pred = np.array([1, 1, 1, 0, 1]).reshape(-1, 1)\n",
    "# true values\n",
    "y_true = np.array([1, 1, 0, 0, 1]).reshape(-1, 1)\n",
    "\n",
    "# Calculate Jaccard Index\n",
    "jaccard_index = jaccard_score(y_true, y_pred)\n",
    "\n",
    "# Calculate Jaccard Distance\n",
    "jaccard_distance = 1 - jaccard_index\n",
    "\n",
    "print(\"Jaccard Index:\", jaccard_index)\n",
    "print(\"Jaccard Distance:\", jaccard_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming Distance\n",
    "\n",
    "**Hamming Distance** measures the minimum number of substitutions required to change one string into the other, or equivalently, the minimum number of errors that could have transformed one string into the other. </br>\n",
    "\n",
    "For more please see [wiki](https://en.wikipedia.org/wiki/Hamming_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Hamming Distance in full functional form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(string1: str, string2: str) -> int:\n",
    "    \"\"\"Return the Hamming distance between two strings.\"\"\"\n",
    "    if len(string1) != len(string2):\n",
    "        raise ValueError(\"Strings must be of equal length.\")\n",
    "    dist_counter = 0\n",
    "    for n in range(len(string1)):\n",
    "        if string1[n] != string2[n]:\n",
    "            dist_counter += 1\n",
    "    return dist_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short hand form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(char1 != char2 for char1, char2 in zip(\"user\", \"uses\", strict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_distance(\"user\", \"uses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Similarity\n",
    "\n",
    "When a chemical structure occurs as a part of a larger chemical structure, the former is called a substructure and the latter is called a superstructure. For example, ethanol is a substructure of acetic acid, and acetic acid is a superstructure of ethanol.\n",
    "\n",
    "Structural similarity is used to determine whether two chemical formulae are similar to each other in that one is the superstructure or substructure of the other.\n",
    "\n",
    "To determine whether A is a *superstructure* of B, use the following formula:\n",
    "\n",
    "$$D=(A \\& B\\bar=B) ? 0: \\infty$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- A is the binary representation of a chemical formula to be retrieved\n",
    "- B is the binary representation of a chemical formula in the database\n",
    "Once it returns 0, A is not a superstructure of B. Otherwise, the result is the other way around.\n",
    "\n",
    "To determine whether A is a *substructure* of B, use the following formula:\n",
    "\n",
    "$$D=(A \\& B\\bar=A) ? 0: \\infty$$\n",
    "\n",
    "Once it returns 0, A is not a substructure of B. Otherwise, the result is the other way around."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

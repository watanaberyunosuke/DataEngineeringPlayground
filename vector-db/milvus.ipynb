{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milvus Database\n",
    "\n",
    "ilvus is a powerful vector database tailored for processing and searching extensive vector data.</br>\n",
    "For more information please see: https://milvus.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python SDK\n",
    "# %pip install pymilvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymilvus\n",
    "pymilvus.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using lite version. Create local database or connect to local database (as a file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"milvus_demo.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"demo_collection\",\n",
    "    dimension=768  # The vectors we will use in this demo has 768 dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Represent text with vectors\n",
    "First, install the model library. This package includes essential ML tools such as PyTorch. The package download may take some time if your local environment has never installed PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"pymilvus[model]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/data-engineering/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/opt/homebrew/anaconda3/envs/data-engineering/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim: 768 (768,)\n",
      "Data has 3 entities, each with fields:  dict_keys(['id', 'vector', 'text', 'subject'])\n",
      "Vector dim: 768\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "\n",
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "# import os\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# This will download a small embedding model \"paraphrase-albert-small-v2\" (~50MB).\n",
    "embedding_fn = model.DefaultEmbeddingFunction()\n",
    "\n",
    "# Text strings to search from.\n",
    "docs = [\n",
    "    \"Artificial intelligence was founded as an academic discipline in 1956.\",\n",
    "    \"Alan Turing was the first person to conduct substantial research in AI.\",\n",
    "    \"Born in Maida Vale, London, Turing was raised in southern England.\",\n",
    "]\n",
    "\n",
    "vectors = embedding_fn.encode_documents(docs)\n",
    "# The output vector has 768 dimensions, matching the collection that we just created.\n",
    "print(\"Dim:\", embedding_fn.dim, vectors[0].shape)  # Dim: 768 (768,)\n",
    "\n",
    "# Each entity has id, vector representation, raw text, and a subject label that we use\n",
    "# to demo metadata filtering later.\n",
    "data = [ {\"id\": i, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"history\"} for i in range(len(vectors)) ]\n",
    "\n",
    "print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Alternative] Use Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Text strings to search from.\n",
    "# docs = [\n",
    "#     \"Artificial intelligence was founded as an academic discipline in 1956.\",\n",
    "#     \"Alan Turing was the first person to conduct substantial research in AI.\",\n",
    "#     \"Born in Maida Vale, London, Turing was raised in southern England.\",\n",
    "# ]\n",
    "# # Use fake representation with random vectors (768 dimension).\n",
    "# vectors = [ [ random.uniform(-1, 1) for _ in range(768) ] for _ in docs ]\n",
    "# data = [ {\"id\": i, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"history\"} for i in range(len(vectors)) ]\n",
    "\n",
    "# print(\"Data has\", len(data), \"entities, each with fields: \", data[0].keys())\n",
    "# print(\"Vector dim:\", len(data[0][\"vector\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'insert_count': 3, 'ids': [0, 1, 2], 'cost': 0}\n"
     ]
    }
   ],
   "source": [
    "res = client.insert(\n",
    "    collection_name=\"demo_collection\",\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search\n",
    "Now we can do semantic searches by representing the search query text as vector, and conduct vector similarity search on Milvus.\n",
    "\n",
    "## Vector search\n",
    "Milvus accepts one or multiple vector search requests at the same time. The value of the query_vectors variable is a list of vectors, where each vector is an array of float numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [\"[{'id': 2, 'distance': 0.5859944224357605, 'entity': {'text': 'Born in Maida Vale, London, Turing was raised in southern England.', 'subject': 'history'}}, {'id': 1, 'distance': 0.5118255615234375, 'entity': {'text': 'Alan Turing was the first person to conduct substantial research in AI.', 'subject': 'history'}}]\"] , extra_info: {'cost': 0}\n"
     ]
    }
   ],
   "source": [
    "query_vectors = embedding_fn.encode_queries([ \"Who is Alan Turing?\" ])\n",
    "\n",
    "# Alternative when using fake data\n",
    "# If you don't have the embedding function you can use a fake vector to finish the demo:\n",
    "# query_vectors = [ [ random.uniform(-1, 1) for _ in range(768) ] ]\n",
    "\n",
    "res = client.search(\n",
    "    collection_name=\"demo_collection\", # target collection\n",
    "    data=query_vectors,                # query vectors\n",
    "    limit=2,                           # number of returned entities\n",
    "    output_fields=[\"text\", \"subject\"], # specifies fields to be returned\n",
    ")\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search with Metadata Filtering\n",
    "\n",
    "You can also conduct vector search while considering the values of the metadata (called \"scalar\" fields in Milvus, as scalar refers to non-vector data). This is done with a filter expression specifying certain criteria. Let's see how to search and filter with the subject field in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [\"[{'id': 3, 'distance': 0.2703056335449219, 'entity': {'text': 'Computational synthesis with AI algorithms predicts molecular properties.', 'subject': 'biology'}}, {'id': 2, 'distance': 0.1642589271068573, 'entity': {'text': 'Machine learning has been used for drug design.', 'subject': 'biology'}}]\"] , extra_info: {'cost': 0}\n"
     ]
    }
   ],
   "source": [
    "# Insert more docs in another subject.\n",
    "docs = [\n",
    "    \"Machine learning has been used for drug design.\",\n",
    "    \"Computational synthesis with AI algorithms predicts molecular properties.\",\n",
    "    \"DDR1 is involved in cancers and fibrosis.\",\n",
    "]\n",
    "vectors = embedding_fn.encode_documents(docs)\n",
    "data = [ {\"id\": 2+i, \"vector\": vectors[i], \"text\": docs[i], \"subject\": \"biology\"} for i in range(len(vectors))]\n",
    "\n",
    "client.insert(\n",
    "    collection_name=\"demo_collection\",\n",
    "    data=data\n",
    ")\n",
    "\n",
    "# This will exclude any text in \"history\" subject despite close to the query vector.\n",
    "res = client.search(\n",
    "    collection_name=\"demo_collection\",\n",
    "    data=embedding_fn.encode_queries([ \"tell me AI related information\" ]),\n",
    "    filter=\"subject == 'biology'\",\n",
    "    limit=2,\n",
    "    output_fields=[\"text\", \"subject\"],\n",
    ")\n",
    "\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "A `query()` is an operation that retrieves all entities matching a cretria, such as a filter expression or matching some ids.\n",
    "\n",
    "For example, the following cell retrieving all entities whose scalar field has a particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.query(\n",
    "    collection_name=\"demo_collection\",\n",
    "    filter=\"subject == 'history'\",\n",
    "    output_fields=[\"text\", \"subject\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly retrieve entities by primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.query(\n",
    "    collection_name=\"demo_collection\",\n",
    "    ids=[0,2],\n",
    "    output_fields=[\"vector\", \"text\", \"subject\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Entity\n",
    "To purge data: delete entities specifying the primary key or delete all entities matching a particular filter expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2]\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Delete entity by PK\n",
    "res = client.delete(collection_name=\"demo_collection\", ids=[0, 2])\n",
    "\n",
    "print(res)\n",
    "\n",
    "# Delete entities by a filter expression\n",
    "res = client.delete(\n",
    "    collection_name=\"demo_collection\",\n",
    "    filter=\"subject == 'biology'\",\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Existing Data\n",
    "Since all data of Milvus Lite is stored in a local file, you can load all data into memory even after the program terminates, by creating a `MilvusClient` with the existing file. For example, this will recover the collections from \"milvus_demo.db\" file and continue to write data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(\"milvus_demo.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all the data in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.drop_collection(collection_name=\"demo_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to external Milvus instance, for example, docker local instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MilvusClient(uri=\"http://localhost:19530\", token=\"root:Milvus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
